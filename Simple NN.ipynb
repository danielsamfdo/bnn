{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"datasets/breast-cancer-wisconsin.csv\",sep=',')\n",
    "df = shuffle(df)\n",
    "train_end = 500\n",
    "\n",
    "train_df = df[:train_end]\n",
    "test_df = df[train_end:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getDS(df):\n",
    "    df1 = df.iloc[:,1:10]\n",
    "    df2 = df.iloc[:,10]\n",
    "    y = np.array(df2)\n",
    "    y[y==4]=1 # malignant\n",
    "    y[y==2]=0 # benign\n",
    "    X = np.array(df1)\n",
    "    X = X.astype(float)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = getDS(train_df)\n",
    "test = getDS(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(9, 50)\n",
    "        self.fc2 = nn.Linear(50, 2)\n",
    "        self.scores = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.tanh(self.fc1(x))\n",
    "#         print x.grad_fn\n",
    "        x = self.fc2(x)\n",
    "        x = self.scores(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# pla = Net()\n",
    "# pla = BinaryNetwork(9,50,2)\n",
    "# for i, data in enumerate(train_dataloader, 0):\n",
    "\n",
    "#     # get the inputs\n",
    "#     inputs, labels = data['X'], data['classes']\n",
    "# # wrap them in Variable\n",
    "# inputs, labels = Variable(inputs.float()), Variable(labels)\n",
    "# optimizer = optim.SGD(pla.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# # zero the parameter gradients\n",
    "# optimizer.zero_grad()\n",
    "# pla.forward(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CancerDataset(Dataset):\n",
    "    \"\"\"CancerDataset.\"\"\"\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.X.shape[0])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = {'X': self.X[idx], 'classes': self.y[idx]}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_ds = CancerDataset(train[0],train[1])\n",
    "test_ds = CancerDataset(test[0],test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_ds, batch_size=20,shuffle=True, num_workers=4)\n",
    "test_dataloader = DataLoader(test_ds, batch_size=20,shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_time(net, train_dataloader):\n",
    "    criterion = nn.NLLLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "    net.train()\n",
    "    \n",
    "    for epoch in range(100):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_dataloader, 0):\n",
    "            # get the inputs\n",
    "            inputs, labels = data['X'], data['classes']\n",
    "            # wrap them in Variable\n",
    "            inputs, labels = Variable(inputs.float()), Variable(labels)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.data[0]\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Finished Training')\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_time(net, test_dataloader):\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    criterion = nn.NLLLoss()\n",
    "    for batch_idx, data in enumerate(test_dataloader):\n",
    "        inputs, labels = data['X'], data['classes']\n",
    "        inputs, targets = Variable(inputs.float()), Variable(labels)\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        test_loss += loss.data[0]\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets.data).cpu().sum()\n",
    "    print \"test set Accuracy\", correct/float(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "tnet = Net()\n",
    "tnet = train_time(tnet,train_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set Accuracy 0.968\n"
     ]
    }
   ],
   "source": [
    "test_time(tnet,train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BinarizeWeights(torch.autograd.Function):\n",
    "    def __init__(self):\n",
    "        super(BinarizeWeights, self).__init__()\n",
    "    \n",
    "    def forward(self, input, S):\n",
    "        self.save_for_backward(S)\n",
    "        res = torch.sign(input)\n",
    "        return res\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        \"\"\"\n",
    "        In the backward pass we receive a Tensor containing the gradient of the loss\n",
    "        with respect to the output, and we need to compute the gradient of the loss\n",
    "        with respect to the input.\n",
    "        \"\"\"\n",
    "        S, = self.saved_tensors\n",
    "        grad_input = torch.mm(grad_output, S)\n",
    "        return grad_input\n",
    "\n",
    "    \n",
    "\n",
    "class BinaryLayer(nn.Linear):\n",
    "    #initialize the Binary Layer where weights are binarized\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(BinaryLayer, self).__init__(input_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.new_weight = BinarizeWeights()(self.weight,x)\n",
    "        # print self.new_weight.grad_fn\n",
    "        backup_weight = self.weight.data\n",
    "        self.weight.data = self.new_weight.data\n",
    "        out = super(BinaryLayer, self).forward(x)\n",
    "        return out\n",
    "\n",
    "class Binaryactivation(torch.autograd.Function):\n",
    "    #initialize the Binary Activation Function after Tanh\n",
    "    def __init__(self):\n",
    "        super(Binaryactivation, self).__init__()\n",
    "        \n",
    "    def forward(self, input):\n",
    "        self.save_for_backward(input)\n",
    "        out = torch.sign(input)\n",
    "        return out\n",
    "    \n",
    "    def backward(self, grad_output):\n",
    "        \"\"\"\n",
    "        In the backward pass we receive a Tensor containing the gradient of the loss\n",
    "        with respect to the output, and we need to compute the gradient of the loss\n",
    "        with respect to the input.\n",
    "        \"\"\"\n",
    "        input, = self.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        grad_input[torch.abs(input) >= 1] = 0\n",
    "        return grad_input\n",
    "\n",
    "\n",
    "    \n",
    "class BinarytanH(torch.autograd.Function):\n",
    "    #initialize the Binary Activation Function after Tanh\n",
    "    def __init__(self):\n",
    "        super(BinarytanH, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        res = F.tanh(x)\n",
    "        out = Binaryactivation()(res)\n",
    "#         print out.grad_fn\n",
    "        return out\n",
    "\n",
    "\n",
    "class BinaryNetwork(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(BinaryNetwork, self).__init__()\n",
    "        self.linear1 = BinaryLayer(D_in, H)\n",
    "        self.linear2 = BinaryLayer(H, D_out)\n",
    "        self.binarized_tanh = BinarytanH()\n",
    "        self.scores = nn.Softmax()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        linear_1 = self.linear1(x)\n",
    "        activation_1 = self.binarized_tanh.forward(linear_1)\n",
    "        smax_1 = self.linear2(activation_1)\n",
    "        output = self.scores(smax_1)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "binet = BinaryNetwork(9,50,2)\n",
    "binet = train_time(binet,train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set Accuracy 0.43\n"
     ]
    }
   ],
   "source": [
    "test_time(binet,train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [pytorchnn]",
   "language": "python",
   "name": "Python [pytorchnn]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
